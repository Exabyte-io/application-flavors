# General test configuration options

# Python files will be copied from this directory
asset_path: ../../assets/python/ml/

# Specific assets that are needed for the test (such as a pre-rendered settings.py)
fixtures:
  path: "fixtures"
  settings: settings.py
  regression:
    training_set_name: regression_training_data.csv
    predict_set_name: regression_predict_data.csv
  classification:
    training_set_name: classification_training_data.csv
    predict_set_name: classification_predict_data.csv
  clustering:
    training_set_name: clustering_blobs.csv
    predict_set_name: clustering_blobs.csv

# Specific files and directories to remove during test cleanup
files_to_remove:
  - settings.py
  - .job_context

# Specific extensions to remove during test cleanup
extensions_to_remove:
  - .csv
  - .png
  - .pyi

# ============================================================================
# Shorthand definitions for the various flavors we've made so far. Used in the "Test Cases" document below.
# Naming convention is <some_prefix>_<short_string_for_file>
#
# Prefixes below:
# IO - I/O
# PRE - Pre-Processing
# REG - Regression
# CLS - Classification
# UNS - Unsupervised
# POS - Post-Processing
#
# The short strings for files are generally based on their name. For example:
# ttSplit = train_test_split
# minMaxScale = min_max_scaler
# kernelRidge = kernelized_ridge_regression
# gradBoostTree = gradboosted_trees_regression

unit_shortnames:

  # I/O Units
  IO_readCSV: "pyml:data_input:read_csv:pandas.pyi"
  IO_ttSplit: "pyml:data_input:train_test_split:sklearn.pyi"

  # Pre-Processors
  PRE_minMaxScale: "pyml:pre_processing:min_max_scaler:sklearn.pyi"
  PRE_dropDupes: "pyml:pre_processing:remove_duplicates:pandas.pyi"
  PRE_dropMissing: "pyml:pre_processing:remove_missing:pandas.pyi"
  PRE_standScale: "pyml:pre_processing:standardization:sklearn.pyi"

  # Regressors
  REG_adaBoostTree: "pyml:model:adaboosted_trees_regression:sklearn.pyi"
  REG_bagTree: "pyml:model:bagged_trees_regression:sklearn.pyi"
  REG_gradBoostTree: "pyml:model:gradboosted_trees_regression:sklearn.pyi"
  REG_ExtremegradBoostTree: "pyml:model:extreme_gradboosted_trees_regression:sklearn.pyi"
  REG_kernelRidge: "pyml:model:kernel_ridge_regression:sklearn.pyi"
  REG_lasso: "pyml:model:lasso_regression:sklearn.pyi"
  REG_mlp: "pyml:model:multilayer_perceptron:sklearn.pyi"
  REG_randomForest: "pyml:model:random_forest_regression:sklearn.pyi"
  REG_RidgeReg: "pyml:model:ridge_regression:sklearn.pyi"

  # Classifiers
  CLS_randomForest: "pyml:model:random_forest_classification:sklearn.pyi"
  CLS_gradBoostTree: "pyml:model:gradboosted_trees_classification:sklearn.pyi"
  CLS_ExtremegradBoostTree: "pyml:model:extreme_gradboosted_trees_classification:sklearn.pyi"

  # Unsupervised Learners
  UNS_kMeans: "pyml:model:k_means_clustering:sklearn.pyi"

  # Post-Processors
  POS_plotParity: "pyml:post_processing:parity_plot:matplotlib.pyi"
  POS_plotClusters: "pyml:post_processing:pca_2d_clusters:matplotlib.pyi"
  POS_plotROC: "pyml:post_processing:roc_curve:sklearn.pyi"

# ============================================================================
# Test cases
# Each key represents a different test name
# Each value underneath the key represents a shorthand for a file (see above)
# Scripts wil be executed in the exact sequence that they are given in

tests:

  # IO flavors - the two IO flavors are quite distinct, so placeing them into 2 categories
  # 1. io_read_csv - can be split into 3 categories based on data category related conditions within the flavor
  #     1a. io_read_csv_regression
  #     1b. io_read_csv_classification
  #     1c. io_read_csv_clustering
  # 2. io_train_test_split - can stay one category and use regression data as default
  IO_Read_Reg:
    category: io_read_csv_regression
    units_to_run:
      - IO_readCSV

  IO_Read_Cls:
    category: io_read_csv_classification
    units_to_run:
      - IO_readCSV

  IO_Read_Uns:
    category: io_read_csv_clustering
    units_to_run:
      - IO_readCSV

  IO_Split_Reg:
    category: io_train_test_split_regression
    units_to_run:
      - IO_ttSplit

  # Pre Processing flavors - only need to test on one type of data, use regression
  Pre_Reg:
    category: pre_processing_regression
    units_to_run:
      - PRE_minMaxScale
      - PRE_standScale
      - PRE_dropDupes
      - PRE_dropMissing

  # Model flavors - split into three categories: 'model_regression', 'model_classification', and 'model_clustering'
  # Regression
  Mod_Reg:
    category: model_regression
    units_to_run:
      - REG_adaBoostTree
      - REG_bagTree
      - REG_gradBoostTree
      - REG_ExtremegradBoostTree
      - REG_kernelRidge
      - REG_lasso
      - REG_mlp
      - REG_randomForest
      - REG_RidgeReg

  # Classification
  Mod_Cls:
    category: model_classification
    units_to_run:
      - CLS_randomForest
      - CLS_gradBoostTree
      - CLS_ExtremegradBoostTree

  # Clustering
  Mod_Uns:
    category: model_clustering
    units_to_run:
      - UNS_kMeans

  # Post Processing - we have 3 distinct types of post_processors, and they fit the categries of the model flavors
  # That is: 'post_processing_regression', 'post_processing_classification', and 'post_processing_clustering'
  Post_Reg:
    category: post_processing_regression
    units_to_run:
      - POS_plotParity

  Post_Cls:
    category: post_processing_classification
    units_to_run:
      - POS_plotROC

  Post_Uns:
    category: post_processing_clustering
    units_to_run:
      - POS_plotClusters
